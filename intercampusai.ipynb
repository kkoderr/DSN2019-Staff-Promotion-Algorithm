{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abdullahâ€™s Baba Yakub, 38, is the heir apparent to the highly revered Yakub business dynasty. The enterprise has spanned decades with vast investment interest in all the various sectors of the economy.\n",
    "\n",
    "Abdullah has worked for 16 years in Europe and America after his first and second degrees at Harvard University where he studied Engineering and Business Management. He is a very experienced technocrat and a global business leader who rose through the rank to become a Senior Vice President at a leading US business conglomerate.\n",
    "His dad is now 70 and has invited him to take over the company with a mandate to take it to the next level of growth as a sustainable legacy. Abdullah is trusted by his father and his siblings to lead this mandate.\n",
    "\n",
    "On resumption, he had an open house with the staff to share his vision and to listen to them on how to take the business to the next level. Beyond the general operational issues and increasing need for regulatory compliance, one of the issues raised by the staff was a general concern on the process of staff promotion. Many of the staff allege that it is skewed and biased. Abdullah understood the concern and promised to address it in a most scientific way.\n",
    "\n",
    "You have been called in by Abdullah to use your machine learning skills to study the pattern of promotion. With this insight, he can understand the important features among available features that can be used to predict promotion eligibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding and Analytical Approach\n",
    "\n",
    "The problem is a classification problem. The problem can be solved by using features provided in the dataset to predict if an employee should be promoted or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_values():\n",
    "    MISSING_VALUES = full_data.isnull()\n",
    "    for features in full_data.columns.values.tolist():\n",
    "        print(features, '\\n', MISSING_VALUES[features].value_counts(), '\\n')\n",
    "        \n",
    "def encode_feature(ft):\n",
    "    encoded_ft = []\n",
    "    for instance in (ft):\n",
    "        full_data[instance] = preprocessing.LabelEncoder().fit_transform(full_data[instance])\n",
    "        encoded_ft.append(full_data[instance])\n",
    "    return encoded_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On scrolling through the data there are some missing values represented by NaN.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_missing_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values exists only in the Qualifications feature and its about 30.2% of the total data in that column. To know what to do with this issue lets see the significance of this feature to the feature we are trying to predict. Firstly we need to encode it to turn it to an numerical value to allow checking of correlation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualification_class = full_data['Qualification'].unique() \n",
    "qualification_class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Qualification'].replace(np.nan, qualification_class[1], inplace=True)\n",
    "full_data.replace('More than 5', 5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_YR_OF_BIRTH = min(full_data['Year_of_birth'])\n",
    "MAX_YR_OF_BIRTH = max(full_data['Year_of_birth'])\n",
    "\n",
    "MIN_YR_OF_REC = min(full_data['Year_of_recruitment'])\n",
    "MAX_YR_OF_REC =max(full_data['Year_of_recruitment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_yr_of_birth = np.linspace(MIN_YR_OF_BIRTH, MAX_YR_OF_BIRTH, 4)\n",
    "\n",
    "bin_yr_of_rec = np.linspace(MIN_YR_OF_REC, MAX_YR_OF_REC, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_birth_labels = ['60s', '50s', 'less than 40']\n",
    "yr_rec_labels = ['35 yrs', '25 yrs', 'less than 15']\n",
    "\n",
    "\n",
    "full_data['Year_of_birth_binned'] = pd.cut(\n",
    "                                    full_data['Year_of_birth'], bin_yr_of_birth, \n",
    "                                    labels=yr_birth_labels, include_lowest=True\n",
    "                                )\n",
    "\n",
    "\n",
    "full_data['Year_of_recruitment_binned'] = pd.cut(\n",
    "                                            full_data['Year_of_recruitment'], \n",
    "                                            bin_yr_of_rec, labels=yr_rec_labels, \n",
    "                                            include_lowest=True\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets group some of the features and observe them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_group = full_data[['Qualification','Targets_met','Last_performance_score']]\n",
    "fd_group = fd_group.groupby(['Qualification'],as_index=False).mean()\n",
    "fd_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table we can see that on average employees with a graduate degree get higher performance score even with a slightly lower met targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_group2 = full_data[['Qualification','Last_performance_score','Promoted_or_Not']]\n",
    "fd_group2 = fd_group2.groupby(['Qualification'],as_index=False).mean()\n",
    "fd_group2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this table we can find that the last performance score has very little to do with whether an employee is promoted or not. The employees with Non-University Education performance score were lower than their counterparts but the have a good chance of being promoted based on the amount of targets met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"Year_of_birth_binned\", y=\"Training_score_average\", data=full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"Targets_met\", y=\"Promoted_or_Not\", data=full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_feature([ 'Year_of_birth_binned', 'Year_of_recruitment_binned', 'Gender', \n",
    "                'Channel_of_Recruitment', 'Foreign_schooled', 'Marital_Status',\n",
    "                'Past_Disciplinary_Action','Previous_IntraDepartmental_Movement',\n",
    "                'Division', 'Qualification','State_Of_Origin'\n",
    "               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = full_data.drop(['EmployeeNo','Year_of_birth', 'Year_of_recruitment', 'Promoted_or_Not'], axis=1)\n",
    "\n",
    "y_data = full_data['Promoted_or_Not']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression().fit(x_train, y_train)\n",
    "lg_pred = logistic_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(lg_pred, y_test, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lests check the performance of our model using the R-square test. A low R-square score means the model did not perform well on the training data that was given to it and that the model paid attention to the noise and did not pick the patterns that lead to good predictions. Besides this, a negative score shows that the model over fitted the data and will perform poorly when given a different set of data to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=245).fit(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(rf_pred, y_test, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in zip(x_data, rf_model.feature_importances_):\n",
    "    print(i, ' ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
